{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\python.exe: No module named pip3\n",
      "c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\python.exe: No module named pip3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (1.19.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\majid\\appdata\\roaming\\python\\python37\\site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from xgboost) (1.5.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip3 install pandas\n",
    "!{sys.executable} -m pip3 install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "import xgboost\n",
    "\n",
    "import math\n",
    "pandas.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0        47       100        27        81        57        37        26   \n",
       "1         0        89        27       100        42        75        29   \n",
       "2         0        57        31        68        72        90       100   \n",
       "3         0       100         7        92         5        68        19   \n",
       "4         0        67        49        83       100       100        81   \n",
       "\n",
       "   feature7  feature8  feature9  feature10  feature11  feature12  feature13  \\\n",
       "0         0         0        23         56         53        100         90   \n",
       "1        45        15        15         37          0         69          2   \n",
       "2       100        76        75         50         51         28         25   \n",
       "3        45        86        34        100         45         74         23   \n",
       "4        80        60        60         40         40         33         20   \n",
       "\n",
       "   feature14  feature15  label  \n",
       "0         40         98      8  \n",
       "1        100          6      2  \n",
       "2         16          0      1  \n",
       "3         67          0      4  \n",
       "4         47          0      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pandas.read_csv('dataset/data_train.csv', header=None, names=['feature'+str(i) for i in range(16)]+['label'])\n",
    "test_data = pandas.read_csv('dataset/data_test.csv', header=None, names=['feature'+str(i) for i in range(16)]+['label'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A: Train a random forecst classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features=3, n_estimators=15,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=15, max_features=3, max_depth=3, random_state=0)  # random forest with 15 tree\n",
    "features = train_data.columns\n",
    "rf_clf.fit(train_data[features[:-1]], train_data[features[-1]])  # train random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict labels for test data and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score: 0.786\n",
      "accuracy: 0.791\n",
      "confusion matrix:\n",
      "[[315   4   0   0   0   0   1   3  40   0]\n",
      " [  0 188 135   1   2   0   0   0   0  38]\n",
      " [  0  18 342   1   1   0   0   2   0   0]\n",
      " [  0   7   0 328   0   0   0   0   0   1]\n",
      " [  0   2   0   1 354   0   0   0   0   7]\n",
      " [  0   0   0 116  13 162   0   0   6  38]\n",
      " [  3   0   2   3   0   0 297  29   2   0]\n",
      " [  0  22  10   3   0   3   3 294   0  29]\n",
      " [ 16   0   0   0   0  12   2  22 283   1]\n",
      " [  0  52   0  63  13   0   2   0   2 204]]\n"
     ]
    }
   ],
   "source": [
    "features = test_data.columns\n",
    "rf_predicted = rf_clf.predict(test_data[features[:-1]])  # predict labels for test data\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test_data['label'], rf_predicted)  # calculate confusion matrix\n",
    "f1_score = metrics.f1_score(test_data['label'], rf_predicted, average='weighted')\n",
    "accuracy = metrics.accuracy_score(test_data['label'], rf_predicted)\n",
    "\n",
    "print('f1-score: {:.3f}'.format(f1_score))\n",
    "print('accuracy: {:.3f}'.format(accuracy))\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B: Train Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator=base_classifier, n_estimators=10, random_state=0) # adaboost with 10 decision tree\n",
    "features = train_data.columns\n",
    "adaboost_clf.fit(train_data[features[:-1]], train_data[features[-1]])  # train adaboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test and evaluate adabost classifier with 10 decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with 10 decision tree:\n",
      "   f1-score: 0.654\n",
      "   accuracy: 0.669\n",
      "   confusion matrix:\n",
      "[[315   4   0   0   0   0   1   3  40   0]\n",
      " [  0 188 135   1   2   0   0   0   0  38]\n",
      " [  0  18 342   1   1   0   0   2   0   0]\n",
      " [  0   7   0 328   0   0   0   0   0   1]\n",
      " [  0   2   0   1 354   0   0   0   0   7]\n",
      " [  0   0   0 116  13 162   0   0   6  38]\n",
      " [  3   0   2   3   0   0 297  29   2   0]\n",
      " [  0  22  10   3   0   3   3 294   0  29]\n",
      " [ 16   0   0   0   0  12   2  22 283   1]\n",
      " [  0  52   0  63  13   0   2   0   2 204]]\n"
     ]
    }
   ],
   "source": [
    "def test_and_eval_adaboost(adaboost_clf, test_data, show_confusion_matrix):\n",
    "    \"\"\" This function gets a adaboost classifier and test data then predists labels of test data and evaluates results \"\"\"\n",
    "    features = test_data.columns\n",
    "    adaboost_predicted = adaboost_clf.predict(test_data[features[:-1]])  # predict labels for test data\n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(test_data['label'], rf_predicted)  # calculate confusion matrix\n",
    "    f1_score = metrics.f1_score(test_data['label'], adaboost_predicted, average='weighted')\n",
    "    accuracy = metrics.accuracy_score(test_data['label'], adaboost_predicted)\n",
    "\n",
    "    print('   f1-score: {:.3f}'.format(f1_score))\n",
    "    print('   accuracy: {:.3f}'.format(accuracy))\n",
    "    if show_confusion_matrix:\n",
    "        print('   confusion matrix:')\n",
    "        print(confusion_matrix)\n",
    "\n",
    "print('AdaBoost with 10 decision tree:')\n",
    "test_and_eval_adaboost(adaboost_clf, test_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C: Repeat AdaBoost classifier with 5, 20 and 50 decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost with 5 decision tree: \n",
      "   f1-score: 0.580\n",
      "   accuracy: 0.601\n",
      "AdaBoost with 10 decision tree: \n",
      "   f1-score: 0.654\n",
      "   accuracy: 0.669\n",
      "AdaBoost with 20 decision tree: \n",
      "   f1-score: 0.759\n",
      "   accuracy: 0.771\n",
      "AdaBoost with 50 decision tree: \n",
      "   f1-score: 0.777\n",
      "   accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "features = train_data.columns\n",
    "base_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "for n_estimator in [5, 10, 20, 50]:\n",
    "    adaboost_clf = AdaBoostClassifier(base_estimator=base_classifier, n_estimators=n_estimator, random_state=0)\n",
    "    adaboost_clf.fit(train_data[features[:-1]], train_data[features[-1]])  # train adaboost \n",
    "    print('AdaBoost with {} decision tree: '.format(n_estimator))\n",
    "    test_and_eval_adaboost(adaboost_clf, test_data, False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part D: Use XGBoost as classifier and find best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split train data to train and validation data to find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_xgb = train_data.sample(frac=0.80, random_state=159)\n",
    "val_for_xgb = train_data.drop(train_for_xgb.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define different values for XGBoost parameters and find best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\majid\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "PARAMETERS = {\"subsample\":[0.5, 0.75, 1], \"colsample_bytree\":[0.3, 0.5, 0.75, 1], \"max_depth\":[3,8, 12],\n",
    "              \"min_child_weight\":[1,5,15], \"learning_rate\":[0.01, 0.1, 0.2], \"n_estimators\":[10, 20, 50]}  # different params\n",
    "features = train_for_xgb.columns\n",
    "model = xgboost.XGBClassifier(n_jobs=-1, eval_metric='mlogloss')\n",
    "model_with_greed_search = GridSearchCV(model, param_grid=PARAMETERS, cv=2, scoring=\"accuracy\")\n",
    "eval_set = [(train_for_xgb[features[:-1]], train_for_xgb['label']), (val_for_xgb[features[:-1]], val_for_xgb['label'])]\n",
    "model_with_greed_search.fit(train_for_xgb[features[:-1]], train_for_xgb['label'], eval_set=eval_set, \n",
    "                            early_stopping_rounds=10, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parametes:\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('Best parametes:')\n",
    "print(model_with_greed_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test XGBoost model for test data and evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with best parameters:\n",
      "   f1-score: 0.967\n",
      "   accuracy: 0.967\n",
      "   confusion matrix:\n",
      "[[342   0   0   0   0   0   0   0  21   0]\n",
      " [  0 341  20   1   0   1   0   1   0   0]\n",
      " [  0   2 361   1   0   0   0   0   0   0]\n",
      " [  0   3   0 332   0   0   0   0   0   1]\n",
      " [  0   0   0   0 362   1   1   0   0   0]\n",
      " [  0   0   0   8   0 322   0   0   2   3]\n",
      " [  0   0   0   0   0   0 334   0   2   0]\n",
      " [  0  27   2   0   0   0   0 329   0   6]\n",
      " [  2   0   0   0   0   1   0   0 333   0]\n",
      " [  0   3   0   2   0   0   0   2   1 328]]\n"
     ]
    }
   ],
   "source": [
    "features = test_data.columns\n",
    "xgb_predictions = model_with_greed_search.predict(test_data[features[:-1]])  # predict labels of test data\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(test_data['label'], xgb_predictions)  # calculate confusion matrix\n",
    "f1_score = metrics.f1_score(test_data['label'], xgb_predictions, average='weighted')\n",
    "accuracy = metrics.accuracy_score(test_data['label'], xgb_predictions)\n",
    "\n",
    "print(\"XGBoost with best parameters:\")\n",
    "print('   f1-score: {:.3f}'.format(f1_score))\n",
    "print('   accuracy: {:.3f}'.format(accuracy))\n",
    "print('   confusion matrix:')\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
